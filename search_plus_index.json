{"./":{"url":"./","title":"充值与费用查询","keywords":"","body":"充值与费用查询 1.1.充值说明 网页端在线充值暂时仅支持微信支付，充值金额实时到账。如您是大客户可联系我们享受更多充值折扣。 1.1. 产品中途价格调整，如何计费 调价前提交的任务不受影响，调价后提交的任务按调整后的价格计费。 登录平台 点击右上角【工作台】进入管理界面。 3.输入充值金额，点击确认支付，这里会提示进行实名认证。输入真实的姓名及身份证号，作为唯一的管理员认证信息。认证成功后点击【确认支付】会弹出微信支付二维码进行扫码支付即可。 1.2. 查看费用账单 登录平台，点击右上角的【工作台】 点击左侧的计费管理进行查看各指标费用的统计，页面下方列表可以按作业名称和使用时间维度进行筛选查看。 普通用户和子账号用户可以查看自己账号下的费用情况。列表可以按作业名称和时间检索。 "},"test.html":{"url":"test.html","title":"开发环境-推理部署示例","keywords":"","body":"使用vLLM快速部署Qwen2-7B指南 1、 安装vLLM（0.5.5版本）以及所需依赖 apt update && apt install -y build-essential pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple # 2、 qwen/Qwen2-7B-Instruct 模型文件下载 pip install modelscope modelscope download --model qwen/Qwen2-7B-Instruct --local_dir /private/Qwen2-7B Instruct 3、 vLLM启动 Qwen2-7B-Instruct 推理服务 vllm serve ./Qwen2-7B-Instruct/ --trust-remote-code --max_model_len 4096 --served model-name AmphaChat 4、 等待服务启动完成即可 启动成功日志如下： 环境准备 依次点击AI实验室-开发环境-创建按钮进入开发环境创建的详情页。 输入开发环境的基本信息 环境名称：vLLM 资源类型：GPU 规格名称：GPU：1*Nvidia/A100-PCIE-80GB | CPU：16核 64GB（实际使用可根据具体 需要确定资源规格） 镜像类型： 预置镜像及衍生镜像 镜像选择： ampha-registry.h3c.com:8099/ampha/jupyter-pytorch:2.0.0-ubuntu20.04- python3.8.10-cuda11.8-cudnn8 ssh远程开发：关闭（本例不使用远程开发，需要使用可打开） 点击提交创建开发环境 "}}